{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import pickle\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic Symbols\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NOT\n",
    "# CNF creation\n",
    "Start with a list of literals:\n",
    "- Literal -> ~Variable\n",
    "- Literal -> Variable\n",
    "\n",
    "Disjunctions are made from literals or other disjunctions\n",
    "- Disjunction -> Literal | Disjunction\n",
    "- Disjunction -> Literal\n",
    "\n",
    "Conjunctive normal forms (CNF) are made of disjunctions and other CNFs\n",
    "- CNF -> (Disjunction) & CNF\n",
    "- CNF -> (Disjunction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160\n"
     ]
    }
   ],
   "source": [
    "variables = ['a', 'b', 'c', 'd']\n",
    "number_of_disjunctions_to_add  = 1\n",
    "number_of_conjunctions_to_add = 1\n",
    "\n",
    "\n",
    "literals = []\n",
    "for element in variables:\n",
    "        literals.append(element)\n",
    "        literals.append('~'+element)\n",
    "\n",
    "disjunctions = copy.deepcopy(literals)\n",
    "\n",
    "for _ in range(number_of_disjunctions_to_add):\n",
    "    for i in range(len(disjunctions)):\n",
    "        for literal in literals:\n",
    "            if disjunctions[i] is not literal:\n",
    "                disjunctions.append(disjunctions[i]+'|'+literal)\n",
    "\n",
    "conjunctive_normal_forms = []\n",
    "for d in disjunctions:\n",
    "     conjunctive_normal_forms.append('('+str(d)+')')\n",
    "\n",
    "for _ in range(number_of_conjunctions_to_add):\n",
    "    for i in range(len(conjunctive_normal_forms)):\n",
    "        for d in disjunctions:\n",
    "            if conjunctive_normal_forms[i] is not d:\n",
    "                conjunctive_normal_forms.append('('+str(d)+')'+'&'+conjunctive_normal_forms[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPTP Formatting\n",
    "fof(name,formula_type,statement)\n",
    "- name is the name of the formula\n",
    "- formula_type is either axiom or conjecture, for our purposes.\n",
    "- Axioms are facts\n",
    "- Conjectures are what we want to prove/disprove\n",
    "\n",
    "\n",
    "Extra TPTP notes:\n",
    "- ! is the universal quantifier\n",
    "- ? is the existential quantifier\n",
    "- variables are denoted with capital letters\n",
    "- func(C) is a function with variable C\n",
    "- => is the implication operator\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NEGATION\n",
    "- <=> is EQUIVALENCE\n",
    "- = is EQUALITY\n",
    "- != is INEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list()\n",
    "conclusions = list()\n",
    "for e in conjunctive_normal_forms:\n",
    "    statements.append(e)\n",
    "    conclusions.append(e)\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append([\"fof(\\'\"+str(statements[i])+\"\\',axiom,\"+str(statements[i])+\").\",statements[i]])\n",
    "\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append([\"fof(\\'\"+str(conclusions[i])+\"\\',conjecture,\"+str(conclusions[i])+\").\",conclusions[i]])\n",
    "\n",
    "theorum_list = list()\n",
    "\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        input = s[0]+' '+c[0]\n",
    "        plain_text = str(s[1])+\".>\"+str(c[1])+\".\"\n",
    "        theorum_list.append([input,plain_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "\n",
    "for i in range(len(theorum_list)):\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(theorum_list[i][0]))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        found_proofs.append([str(theorum_list[i][0]),result,theorum_list[i][1]])\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(theorum_list[i][0]),result,theorum_list[i][1]])\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_training_data(found, unfound):\n",
    "    input = []\n",
    "    theorum = []\n",
    "    non_theorum = []\n",
    "    for sample in found:\n",
    "        s = sample[2]\n",
    "        r = \"Found\"\n",
    "        proof = sample[1]\n",
    "        input.append([s,r,proof])\n",
    "        theorum.append([s,r,proof])\n",
    "\n",
    "    for sample in unfound:\n",
    "        s = sample[2]\n",
    "        r = \"Unfound\"\n",
    "        proof = sample[1]\n",
    "        input.append([s,r,proof])\n",
    "        non_theorum.append([s,r,proof])\n",
    "    \n",
    "    return [input, theorum, non_theorum]\n",
    "\n",
    "training_data,found,unfound = format_training_data(found_proofs,unfound_proofs)\n",
    "\n",
    "with open('training_data.pickle','wb') as f:\n",
    "    pickle.dump(training_data,f)\n",
    "\n",
    "with open('theorum.pickle','wb') as f:\n",
    "    pickle.dump(found,f)\n",
    "\n",
    "with open('non_theorum.pickle','wb') as f:\n",
    "    pickle.dump(unfound,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
